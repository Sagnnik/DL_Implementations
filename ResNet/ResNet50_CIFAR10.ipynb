{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet50_CIFAR10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GI3ZAi8MiOhn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10"
      ],
      "metadata": {
        "id": "Xo-S8AF1ieT2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = cifar10.load_data()\n",
        "(x_train, y_train), (x_test, y_test) = dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beHv4De6jOXR",
        "outputId": "1406055f-3db5-452b-9fe8-c30730590eb4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "170508288/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes=[\"Airplane\",\"Automobile\",\"Bird\", \"Cat\",\"Deer\",\"Dog\",\"Frog\",\"Horse\",\"Ship\",\"Truck\"]\n",
        "y_train= y_train.reshape(-1,)\n",
        "y_test= y_test.reshape(-1,)\n",
        "y_train[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0FDNwzrjpjd",
        "outputId": "e9984657-3654-483b-fd14-f13a3238e7ca"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 9, 9, 4, 1], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_sample(x,y,index):\n",
        "  plt.figure(figsize=(15,2))\n",
        "  plt.imshow(x[index])\n",
        "  plt.xlabel(classes[y[index]]) "
      ],
      "metadata": {
        "id": "PA98tQmQjwtZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_sample(x_train, y_train, 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "8Yk6s2Hrdem0",
        "outputId": "241efca4-9582-41d6-d3c9-ea873721c693"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x144 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data and converting to float 32 \n",
        "X_train= x_train.astype('float32') / 255.0\n",
        "X_test= x_test.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "pEZVxwtzdh3Y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def res_identity(x, filters):\n",
        "  x_skip = x\n",
        "  f1, f2 = filters\n",
        "\n",
        "  #First Block\n",
        "  x = tf.keras.layers.Conv2D(f1, kernel_size=(1,1), strides=(1,1), padding='valid', kernel_regularizer=tf.keras.regularizers.L2(l2=0.001))(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  #Second Block\n",
        "  x = tf.keras.layers.Conv2D(f1, kernel_size=(3,3), strides=(1,1), padding='same', kernel_regularizer=tf.keras.regularizers.L2(l2=0.001))(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  #Third Block\n",
        "  x = tf.keras.layers.Conv2D(f2, kernel_size=(1,1), strides=(1,1), padding='valid', kernel_regularizer=tf.keras.regularizers.L2(l2=0.001))(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  #Add Residue\n",
        "  x = tf.keras.layers.Add()([x, x_skip])\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "DdG-ptX7dvSG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def res_conv(x, s, filters):\n",
        "  x_skip = x;\n",
        "  f1, f2 = filters;\n",
        "\n",
        "  #First Block\n",
        "  x = tf.keras.layers.Conv2D(f1, kernel_size=(1,1), strides=(s,s), padding='valid', kernel_regularizer=tf.keras.regularizers.L2(l2=0.001))(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  #Second Block\n",
        "  x = tf.keras.layers.Conv2D(f1, kernel_size=(3,3), strides=(1,1), padding='same', kernel_regularizer=tf.keras.regularizers.L2(l2=0.001))(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  #Third Block\n",
        "  x = tf.keras.layers.Conv2D(f2, kernel_size=(1,1), strides=(1,1), padding='valid', kernel_regularizer=tf.keras.regularizers.L2(l2=0.001))(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  #Bottle Neck Layer\n",
        "  x_skip = tf.keras.layers.Conv2D(f2, kernel_size=(1,1), strides=(s,s), padding='valid', kernel_regularizer=tf.keras.regularizers.L2(l2=0.001))(x_skip)\n",
        "  x_skip = tf.keras.layers.BatchNormalization()(x_skip)\n",
        "  #Add Residue\n",
        "  x = tf.keras.layers.Add()([x, x_skip])\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "k7qwrr0UjCoE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shape = x_train.shape[1], x_train.shape[2], x_train.shape[3]\n",
        "print(shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rd5bHKYlKzY",
        "outputId": "298acd6c-4ee0-4f28-b5a9-2234bd90bc3d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def resnet50(shape, classes=10):\n",
        "  x_input = tf.keras.layers.Input(shape)\n",
        "  x = tf.keras.layers.ZeroPadding2D(padding=(3,3))(x_input)\n",
        "  #1st Stage with Maxpooling\n",
        "  x = tf.keras.layers.Conv2D(64, kernel_size=(7,7), strides=(2,2)) (x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  x = tf.keras.layers.MaxPooling2D(pool_size=(3,3), strides=(2,2))(x)\n",
        "  #2nd Stage\n",
        "  x = res_conv(x, s=1, filters=(64, 256))\n",
        "  x = res_identity(x, filters=(64, 256))\n",
        "  x = res_identity(x, filters=(64, 256))\n",
        "  #3rd Stage\n",
        "  x = res_conv(x, s=2, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  #4th Stage\n",
        "  x = res_conv(x, s=2, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  #5th Stage\n",
        "  x = res_conv(x, s=2, filters=(512, 2048))\n",
        "  x = res_identity(x, filters=(512, 2048))\n",
        "  x = res_identity(x, filters=(512, 2048))\n",
        "\n",
        "  x = tf.keras.layers.AveragePooling2D(strides=(2,2), padding='same')(x)\n",
        "  x = tf.keras.layers.Flatten()(x)\n",
        "  x = tf.keras.layers.Dense(classes, activation='softmax', kernel_initializer='he_normal')(x)\n",
        "  #Define the Model\n",
        "  model = tf.keras.models.Model(inputs=x_input, outputs=x, name='ResNet50')\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Sb0nhygjkw0n"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet50(shape)\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYjvYHxZ4_bP",
        "outputId": "74a9c89f-3f60-4f11-e8fe-28fd47d2eea1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " zero_padding2d (ZeroPadding2D)  (None, 38, 38, 3)   0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 16, 16, 64)   9472        ['zero_padding2d[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 16, 16, 64)  256         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 16, 16, 64)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 7, 7, 64)     0           ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 7, 7, 64)     4160        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 7, 7, 64)    256         ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 7, 7, 64)     0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 7, 7, 64)     36928       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 7, 7, 64)    256         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 7, 7, 64)     0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 7, 7, 256)    16640       ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 7, 7, 256)    16640       ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 7, 7, 256)   1024        ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 7, 7, 256)   1024        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 7, 7, 256)    0           ['batch_normalization_3[0][0]',  \n",
            "                                                                  'batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 7, 7, 256)    0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 7, 7, 64)     16448       ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 7, 7, 64)    256         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 7, 7, 64)     0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 7, 7, 64)     36928       ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 7, 7, 64)    256         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 7, 7, 64)     0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 7, 7, 256)    16640       ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 7, 7, 256)   1024        ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 7, 7, 256)    0           ['batch_normalization_7[0][0]',  \n",
            "                                                                  'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 7, 7, 256)    0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 7, 7, 64)     16448       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 7, 7, 64)    256         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 7, 7, 64)     0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 7, 7, 64)     36928       ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 7, 7, 64)    256         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 7, 7, 64)     0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 7, 7, 256)    16640       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 7, 7, 256)   1024        ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 7, 7, 256)    0           ['batch_normalization_10[0][0]', \n",
            "                                                                  'activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 7, 7, 256)    0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 4, 4, 128)    32896       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 4, 4, 128)   512         ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 4, 4, 128)    147584      ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 4, 4, 128)   512         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 4, 4, 512)    66048       ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 4, 4, 512)    131584      ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 4, 4, 512)    0           ['batch_normalization_13[0][0]', \n",
            "                                                                  'batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 4, 4, 512)    0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 4, 4, 128)    65664       ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 4, 4, 128)   512         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 4, 4, 128)    147584      ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 4, 4, 128)   512         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 4, 4, 512)    66048       ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 4, 4, 512)    0           ['batch_normalization_17[0][0]', \n",
            "                                                                  'activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 4, 4, 512)    0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 4, 4, 128)    65664       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 4, 4, 128)   512         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 4, 4, 128)    147584      ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 4, 4, 128)   512         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 4, 4, 512)    66048       ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 4, 4, 512)    0           ['batch_normalization_20[0][0]', \n",
            "                                                                  'activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 4, 4, 512)    0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 4, 4, 128)    65664       ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 4, 4, 128)   512         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 4, 4, 128)    147584      ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 4, 4, 128)   512         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 4, 4, 128)    0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 4, 4, 512)    66048       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 4, 4, 512)   2048        ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 4, 4, 512)    0           ['batch_normalization_23[0][0]', \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 4, 4, 512)    0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 2, 2, 256)    131328      ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 2, 2, 256)    590080      ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 2, 2, 1024)   263168      ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 2, 2, 1024)   525312      ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 2, 2, 1024)  4096        ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 2, 2, 1024)  4096        ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 2, 2, 1024)   0           ['batch_normalization_26[0][0]', \n",
            "                                                                  'batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 2, 2, 1024)   0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 2, 2, 256)    262400      ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 2, 2, 256)    590080      ['activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 2, 2, 1024)   263168      ['activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 2, 2, 1024)  4096        ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 2, 2, 1024)   0           ['batch_normalization_30[0][0]', \n",
            "                                                                  'activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 2, 2, 1024)   0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 2, 2, 256)    262400      ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 2, 2, 256)    590080      ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 2, 2, 1024)   263168      ['activation_29[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 2, 2, 1024)  4096        ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 2, 2, 1024)   0           ['batch_normalization_33[0][0]', \n",
            "                                                                  'activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 2, 2, 1024)   0           ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 2, 2, 256)    262400      ['activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 2, 2, 256)    590080      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 2, 2, 1024)   263168      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 2, 2, 1024)  4096        ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 2, 2, 1024)   0           ['batch_normalization_36[0][0]', \n",
            "                                                                  'activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 2, 2, 1024)   0           ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 2, 2, 256)    262400      ['activation_33[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 2, 2, 256)    590080      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 2, 2, 1024)   263168      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 2, 2, 1024)  4096        ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 2, 2, 1024)   0           ['batch_normalization_39[0][0]', \n",
            "                                                                  'activation_33[0][0]']          \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 2, 2, 1024)   0           ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 2, 2, 256)    262400      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 2, 2, 256)    590080      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 2, 2, 256)   1024        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 2, 2, 256)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 2, 2, 1024)   263168      ['activation_38[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 2, 2, 1024)  4096        ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 2, 2, 1024)   0           ['batch_normalization_42[0][0]', \n",
            "                                                                  'activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 2, 2, 1024)   0           ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 1, 1, 512)    524800      ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 1, 1, 512)    2359808     ['activation_40[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 1, 1, 2048)   1050624     ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 1, 1, 2048)   2099200     ['activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 1, 1, 2048)  8192        ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 1, 1, 2048)  8192        ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 1, 1, 2048)   0           ['batch_normalization_45[0][0]', \n",
            "                                                                  'batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 1, 1, 2048)   0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 1, 1, 512)    1049088     ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 1, 1, 512)    2359808     ['activation_43[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 1, 1, 2048)   1050624     ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 1, 1, 2048)  8192        ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 1, 1, 2048)   0           ['batch_normalization_49[0][0]', \n",
            "                                                                  'activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 1, 1, 2048)   0           ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 1, 1, 512)    1049088     ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 1, 1, 512)    2359808     ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 1, 1, 512)   2048        ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 1, 1, 512)    0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 1, 1, 2048)   1050624     ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 1, 1, 2048)  8192        ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 1, 1, 2048)   0           ['batch_normalization_52[0][0]', \n",
            "                                                                  'activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 1, 1, 2048)   0           ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 1, 1, 2048)  0           ['activation_48[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 2048)         0           ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 10)           20490       ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,608,202\n",
            "Trainable params: 23,555,082\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss= 'sparse_categorical_crossentropy',\n",
        "              optimizer= 'Adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "4F1vufaE5Cfj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, batch_size=64, epochs=160)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lju9Rxg0O6LO",
        "outputId": "d9ec3a1e-f228-4f25-8360-11b54d8ad1bf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/160\n",
            "782/782 [==============================] - 55s 49ms/step - loss: 14.0693 - accuracy: 0.3767\n",
            "Epoch 2/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 7.3226 - accuracy: 0.4121\n",
            "Epoch 3/160\n",
            "782/782 [==============================] - 39s 49ms/step - loss: 5.7804 - accuracy: 0.3225\n",
            "Epoch 4/160\n",
            "782/782 [==============================] - 39s 49ms/step - loss: 4.5346 - accuracy: 0.3542\n",
            "Epoch 5/160\n",
            "782/782 [==============================] - 39s 50ms/step - loss: 3.9773 - accuracy: 0.3746\n",
            "Epoch 6/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 3.7681 - accuracy: 0.3851\n",
            "Epoch 7/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 3.6622 - accuracy: 0.4012\n",
            "Epoch 8/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 3.0649 - accuracy: 0.4283\n",
            "Epoch 9/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 2.6958 - accuracy: 0.4586\n",
            "Epoch 10/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 4.1363 - accuracy: 0.3333\n",
            "Epoch 11/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 2.5232 - accuracy: 0.4408\n",
            "Epoch 12/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 2.7851 - accuracy: 0.4100\n",
            "Epoch 13/160\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 2.4567 - accuracy: 0.4585\n",
            "Epoch 14/160\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 2.3514 - accuracy: 0.4902\n",
            "Epoch 15/160\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 1.8154 - accuracy: 0.5438\n",
            "Epoch 16/160\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 2.0596 - accuracy: 0.5362\n",
            "Epoch 17/160\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 1.5532 - accuracy: 0.5940\n",
            "Epoch 18/160\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 1.7546 - accuracy: 0.6022\n",
            "Epoch 19/160\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 1.7750 - accuracy: 0.6143\n",
            "Epoch 20/160\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 1.3624 - accuracy: 0.6577\n",
            "Epoch 21/160\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 1.7003 - accuracy: 0.6525\n",
            "Epoch 22/160\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 1.3287 - accuracy: 0.6831\n",
            "Epoch 23/160\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 1.1669 - accuracy: 0.7051\n",
            "Epoch 24/160\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 1.1731 - accuracy: 0.7134\n",
            "Epoch 25/160\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 1.1332 - accuracy: 0.7242\n",
            "Epoch 26/160\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 1.1014 - accuracy: 0.7408\n",
            "Epoch 27/160\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 1.0651 - accuracy: 0.7473\n",
            "Epoch 28/160\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 1.0555 - accuracy: 0.7572\n",
            "Epoch 29/160\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 1.0149 - accuracy: 0.7657\n",
            "Epoch 30/160\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 1.0012 - accuracy: 0.7694\n",
            "Epoch 31/160\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 0.9731 - accuracy: 0.7780\n",
            "Epoch 32/160\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 0.9533 - accuracy: 0.7842\n",
            "Epoch 33/160\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 0.9329 - accuracy: 0.7910\n",
            "Epoch 34/160\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 0.9081 - accuracy: 0.7963\n",
            "Epoch 35/160\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 0.9032 - accuracy: 0.8001\n",
            "Epoch 36/160\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 0.8810 - accuracy: 0.8054\n",
            "Epoch 37/160\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 0.8634 - accuracy: 0.8110\n",
            "Epoch 38/160\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 0.8469 - accuracy: 0.8122\n",
            "Epoch 39/160\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 0.8431 - accuracy: 0.8196\n",
            "Epoch 40/160\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 0.8353 - accuracy: 0.8217\n",
            "Epoch 41/160\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 0.8168 - accuracy: 0.8243\n",
            "Epoch 42/160\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 0.8062 - accuracy: 0.8269\n",
            "Epoch 43/160\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 0.8024 - accuracy: 0.8306\n",
            "Epoch 44/160\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 0.7978 - accuracy: 0.8321\n",
            "Epoch 45/160\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 0.7855 - accuracy: 0.8383\n",
            "Epoch 46/160\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 0.7807 - accuracy: 0.8380\n",
            "Epoch 47/160\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 0.7759 - accuracy: 0.8425\n",
            "Epoch 48/160\n",
            "782/782 [==============================] - 39s 49ms/step - loss: 0.7696 - accuracy: 0.8430\n",
            "Epoch 49/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.7594 - accuracy: 0.8448\n",
            "Epoch 50/160\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 0.7503 - accuracy: 0.8488\n",
            "Epoch 51/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.7599 - accuracy: 0.8458\n",
            "Epoch 52/160\n",
            "782/782 [==============================] - 37s 48ms/step - loss: 0.7433 - accuracy: 0.8512\n",
            "Epoch 53/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.7425 - accuracy: 0.8531\n",
            "Epoch 54/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.7363 - accuracy: 0.8531\n",
            "Epoch 55/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.7363 - accuracy: 0.8558\n",
            "Epoch 56/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.7334 - accuracy: 0.8574\n",
            "Epoch 57/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.7278 - accuracy: 0.8569\n",
            "Epoch 58/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.7266 - accuracy: 0.8599\n",
            "Epoch 59/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.7257 - accuracy: 0.8613\n",
            "Epoch 60/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.7176 - accuracy: 0.8602\n",
            "Epoch 61/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.7163 - accuracy: 0.8648\n",
            "Epoch 62/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.7011 - accuracy: 0.8664\n",
            "Epoch 63/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.7121 - accuracy: 0.8632\n",
            "Epoch 64/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.7130 - accuracy: 0.8673\n",
            "Epoch 65/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.7009 - accuracy: 0.8675\n",
            "Epoch 66/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6947 - accuracy: 0.8691\n",
            "Epoch 67/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6974 - accuracy: 0.8692\n",
            "Epoch 68/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.7021 - accuracy: 0.8727\n",
            "Epoch 69/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6936 - accuracy: 0.8734\n",
            "Epoch 70/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6989 - accuracy: 0.8712\n",
            "Epoch 71/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6855 - accuracy: 0.8741\n",
            "Epoch 72/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6920 - accuracy: 0.8714\n",
            "Epoch 73/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6856 - accuracy: 0.8751\n",
            "Epoch 74/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6858 - accuracy: 0.8729\n",
            "Epoch 75/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6915 - accuracy: 0.8754\n",
            "Epoch 76/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6786 - accuracy: 0.8777\n",
            "Epoch 77/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6723 - accuracy: 0.8756\n",
            "Epoch 78/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6845 - accuracy: 0.8780\n",
            "Epoch 79/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6870 - accuracy: 0.8761\n",
            "Epoch 80/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6824 - accuracy: 0.8771\n",
            "Epoch 81/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6777 - accuracy: 0.8790\n",
            "Epoch 82/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6802 - accuracy: 0.8779\n",
            "Epoch 83/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6776 - accuracy: 0.8810\n",
            "Epoch 84/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6646 - accuracy: 0.8802\n",
            "Epoch 85/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6674 - accuracy: 0.8809\n",
            "Epoch 86/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6583 - accuracy: 0.8841\n",
            "Epoch 87/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6672 - accuracy: 0.8843\n",
            "Epoch 88/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6638 - accuracy: 0.8836\n",
            "Epoch 89/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6592 - accuracy: 0.8853\n",
            "Epoch 90/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6620 - accuracy: 0.8850\n",
            "Epoch 91/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6566 - accuracy: 0.8860\n",
            "Epoch 92/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6538 - accuracy: 0.8865\n",
            "Epoch 93/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6661 - accuracy: 0.8851\n",
            "Epoch 94/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6650 - accuracy: 0.8852\n",
            "Epoch 95/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6517 - accuracy: 0.8875\n",
            "Epoch 96/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6499 - accuracy: 0.8865\n",
            "Epoch 97/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6534 - accuracy: 0.8876\n",
            "Epoch 98/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6522 - accuracy: 0.8874\n",
            "Epoch 99/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6460 - accuracy: 0.8895\n",
            "Epoch 100/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6515 - accuracy: 0.8877\n",
            "Epoch 101/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6500 - accuracy: 0.8876\n",
            "Epoch 102/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6533 - accuracy: 0.8863\n",
            "Epoch 103/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6421 - accuracy: 0.8900\n",
            "Epoch 104/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6531 - accuracy: 0.8895\n",
            "Epoch 105/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6424 - accuracy: 0.8904\n",
            "Epoch 106/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6500 - accuracy: 0.8896\n",
            "Epoch 107/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6472 - accuracy: 0.8887\n",
            "Epoch 108/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6468 - accuracy: 0.8884\n",
            "Epoch 109/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6454 - accuracy: 0.8896\n",
            "Epoch 110/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6408 - accuracy: 0.8906\n",
            "Epoch 111/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6414 - accuracy: 0.8906\n",
            "Epoch 112/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6452 - accuracy: 0.8909\n",
            "Epoch 113/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6489 - accuracy: 0.8912\n",
            "Epoch 114/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6387 - accuracy: 0.8912\n",
            "Epoch 115/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6411 - accuracy: 0.8903\n",
            "Epoch 116/160\n",
            "782/782 [==============================] - 39s 49ms/step - loss: 0.6344 - accuracy: 0.8942\n",
            "Epoch 117/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6442 - accuracy: 0.8915\n",
            "Epoch 118/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6279 - accuracy: 0.8962\n",
            "Epoch 119/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6414 - accuracy: 0.8916\n",
            "Epoch 120/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6386 - accuracy: 0.8930\n",
            "Epoch 121/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6458 - accuracy: 0.8928\n",
            "Epoch 122/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6349 - accuracy: 0.8945\n",
            "Epoch 123/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6301 - accuracy: 0.8945\n",
            "Epoch 124/160\n",
            "782/782 [==============================] - 39s 49ms/step - loss: 0.6378 - accuracy: 0.8951\n",
            "Epoch 125/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6358 - accuracy: 0.8941\n",
            "Epoch 126/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6215 - accuracy: 0.8951\n",
            "Epoch 127/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6266 - accuracy: 0.8963\n",
            "Epoch 128/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6369 - accuracy: 0.8935\n",
            "Epoch 129/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6396 - accuracy: 0.8927\n",
            "Epoch 130/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6312 - accuracy: 0.8957\n",
            "Epoch 131/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6376 - accuracy: 0.8948\n",
            "Epoch 132/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6318 - accuracy: 0.8952\n",
            "Epoch 133/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6320 - accuracy: 0.8951\n",
            "Epoch 134/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6238 - accuracy: 0.8935\n",
            "Epoch 135/160\n",
            "782/782 [==============================] - 39s 49ms/step - loss: 0.6177 - accuracy: 0.8988\n",
            "Epoch 136/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6211 - accuracy: 0.8975\n",
            "Epoch 137/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6304 - accuracy: 0.8964\n",
            "Epoch 138/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6216 - accuracy: 0.8978\n",
            "Epoch 139/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6272 - accuracy: 0.8970\n",
            "Epoch 140/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6276 - accuracy: 0.8992\n",
            "Epoch 141/160\n",
            "782/782 [==============================] - 39s 49ms/step - loss: 0.6241 - accuracy: 0.8988\n",
            "Epoch 142/160\n",
            "782/782 [==============================] - 39s 49ms/step - loss: 0.6248 - accuracy: 0.8986\n",
            "Epoch 143/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6283 - accuracy: 0.8949\n",
            "Epoch 144/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6166 - accuracy: 0.9001\n",
            "Epoch 145/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6268 - accuracy: 0.8969\n",
            "Epoch 146/160\n",
            "782/782 [==============================] - 39s 49ms/step - loss: 0.6164 - accuracy: 0.8995\n",
            "Epoch 147/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6223 - accuracy: 0.8978\n",
            "Epoch 148/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6203 - accuracy: 0.8984\n",
            "Epoch 149/160\n",
            "782/782 [==============================] - 39s 49ms/step - loss: 0.6088 - accuracy: 0.9009\n",
            "Epoch 150/160\n",
            "782/782 [==============================] - 39s 49ms/step - loss: 0.6095 - accuracy: 0.8993\n",
            "Epoch 151/160\n",
            "782/782 [==============================] - 39s 49ms/step - loss: 0.6222 - accuracy: 0.8990\n",
            "Epoch 152/160\n",
            "782/782 [==============================] - 39s 49ms/step - loss: 0.6117 - accuracy: 0.9011\n",
            "Epoch 153/160\n",
            "782/782 [==============================] - 39s 49ms/step - loss: 0.6171 - accuracy: 0.8998\n",
            "Epoch 154/160\n",
            "782/782 [==============================] - 39s 49ms/step - loss: 0.6225 - accuracy: 0.8981\n",
            "Epoch 155/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6128 - accuracy: 0.9004\n",
            "Epoch 156/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6179 - accuracy: 0.9010\n",
            "Epoch 157/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6216 - accuracy: 0.8991\n",
            "Epoch 158/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6176 - accuracy: 0.8990\n",
            "Epoch 159/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6128 - accuracy: 0.8991\n",
            "Epoch 160/160\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 0.6142 - accuracy: 0.8997\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f86a01c2a90>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGAR-YuumwZT",
        "outputId": "278db592-68b5-49e5-b2a6-c53e9b5e21d2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 5s 15ms/step - loss: 1.3573 - accuracy: 0.7220\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3573037385940552, 0.722000002861023]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)"
      ],
      "metadata": {
        "id": "NklTsEvqm34x"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_classes = [np.argmax(element) for element in y_pred]\n",
        "y_classes[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRuc18cwnMrv",
        "outputId": "ed490090-8093-4aac-db45-307b730df180"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 1, 8, 8, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvBhdQPUnVFw",
        "outputId": "db00229a-fb7f-4f52-8ded-cf9143940a87"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 8, 8, 0, 6], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_sample(x_test, y_test,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "nhJPU_PdnbOv",
        "outputId": "692bc0c8-01c4-4e7e-de71-01a68297df76"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x144 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes[y_classes[1]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zAEH1G6SnfOd",
        "outputId": "9412dcff-a237-4fc5-a30d-01d0809ae9fb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Automobile'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('ResNet50_weights')"
      ],
      "metadata": {
        "id": "zolBilLBnjMb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_A20uwZEn6RX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}